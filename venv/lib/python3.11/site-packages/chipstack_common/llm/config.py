from chipstack_common.llm.models import (
    OpenAIModelEnum,
    ProviderIdentifier,
)
from dataclasses import asdict, dataclass
from typing import Optional


@dataclass(frozen=True)
class ModelSelection:
    """Represents the options for selecting an LLM."""

    # The provider of the LLM model.
    provider: ProviderIdentifier = ProviderIdentifier.OPENAI

    # The particular LLM model to use from the given provider.
    model: str = OpenAIModelEnum.default().value

    # If this is a TGI model, the URL at which the model is hosted.
    model_base_url: Optional[str] = None


@dataclass(frozen=True)
class InferenceOptions:
    """Represents the options for performing inference against the LLM."""

    temperature: float = 0.1
    max_tokens: int = 4096
    top_p: float = 0.7

    def asdict(self):
        return asdict(self)
